{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 8723316,
          "sourceType": "datasetVersion",
          "datasetId": 5205532
        }
      ],
      "dockerImageVersionId": 30733,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "notebook7b0d2af213",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "tj2552_generate_titles_for_medical_journals_path = kagglehub.dataset_download('tj2552/generate-titles-for-medical-journals')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "EijguX5dZEOY",
        "outputId": "a7631aff-760c-418d-d19d-ccfe1a65c977",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/tj2552/generate-titles-for-medical-journals?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 105M/105M [00:01<00:00, 95.5MB/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-06-30T20:46:14.546147Z",
          "iopub.execute_input": "2024-06-30T20:46:14.546843Z",
          "iopub.status.idle": "2024-06-30T20:46:14.557873Z",
          "shell.execute_reply.started": "2024-06-30T20:46:14.546811Z",
          "shell.execute_reply": "2024-06-30T20:46:14.557001Z"
        },
        "trusted": true,
        "id": "eIYZJPT5ZEOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import json\n",
        "import os\n",
        "\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T20:46:17.397731Z",
          "iopub.execute_input": "2024-06-30T20:46:17.398549Z",
          "iopub.status.idle": "2024-06-30T20:46:17.404767Z",
          "shell.execute_reply.started": "2024-06-30T20:46:17.398519Z",
          "shell.execute_reply": "2024-06-30T20:46:17.403848Z"
        },
        "trusted": true,
        "id": "-OP_FHOzZEOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = \"/kaggle/input/generate-titles-for-medical-journals/sample_titleGeneration_dataset.json\"\n",
        "with open(file) as input_file:\n",
        "    data = json.load(input_file)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T20:46:19.709069Z",
          "iopub.execute_input": "2024-06-30T20:46:19.709856Z",
          "iopub.status.idle": "2024-06-30T20:46:19.741135Z",
          "shell.execute_reply.started": "2024-06-30T20:46:19.709825Z",
          "shell.execute_reply": "2024-06-30T20:46:19.740163Z"
        },
        "trusted": true,
        "id": "FM5hFVTDZEOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (json.dumps(data[0], indent=4))\n",
        "print (\"=\"* 100)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T20:46:21.849915Z",
          "iopub.execute_input": "2024-06-30T20:46:21.850866Z",
          "iopub.status.idle": "2024-06-30T20:46:21.855843Z",
          "shell.execute_reply.started": "2024-06-30T20:46:21.850834Z",
          "shell.execute_reply": "2024-06-30T20:46:21.854917Z"
        },
        "trusted": true,
        "id": "gx3kkDARZEOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (json.dumps(data[1], indent=4))\n",
        "print (\"=\"* 100)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T20:46:24.279101Z",
          "iopub.execute_input": "2024-06-30T20:46:24.279776Z",
          "iopub.status.idle": "2024-06-30T20:46:24.284736Z",
          "shell.execute_reply.started": "2024-06-30T20:46:24.279741Z",
          "shell.execute_reply": "2024-06-30T20:46:24.283867Z"
        },
        "trusted": true,
        "id": "osdK1CA9ZEOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T20:46:30.49081Z",
          "iopub.execute_input": "2024-06-30T20:46:30.491687Z",
          "iopub.status.idle": "2024-06-30T20:46:30.550211Z",
          "shell.execute_reply.started": "2024-06-30T20:46:30.491651Z",
          "shell.execute_reply": "2024-06-30T20:46:30.526627Z"
        },
        "trusted": true,
        "id": "GFfh78ptZEOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T20:46:32.164809Z",
          "iopub.execute_input": "2024-06-30T20:46:32.165551Z",
          "iopub.status.idle": "2024-06-30T20:46:32.179735Z",
          "shell.execute_reply.started": "2024-06-30T20:46:32.165517Z",
          "shell.execute_reply": "2024-06-30T20:46:32.178749Z"
        },
        "trusted": true,
        "id": "h3DCxP-7ZEOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T20:46:37.799763Z",
          "iopub.execute_input": "2024-06-30T20:46:37.800125Z",
          "iopub.status.idle": "2024-06-30T20:46:37.804459Z",
          "shell.execute_reply.started": "2024-06-30T20:46:37.800097Z",
          "shell.execute_reply": "2024-06-30T20:46:37.803503Z"
        },
        "trusted": true,
        "id": "ZV6SrBr7ZEOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
        "\n",
        "print (f\"Original: \\n{df.briefTitle.iloc[0]}\")\n",
        "print (\"\\n\")\n",
        "print (f\"Tokenized: \\n{tokenizer.tokenize(df.briefTitle.iloc[0])}\")\n",
        "\n",
        "df[\"briefTitle_tokenLength\"] = df.briefTitle.apply(lambda x: len(tokenizer.tokenize(x)))\n",
        "df[\"detailedDescription_tokenLength\"] = df.detailedDescription.apply(lambda x: len(tokenizer.tokenize(x)))\n",
        "\n",
        "print (f\"Average briefTitle Length: {df.briefTitle_tokenLength.mean()}\")\n",
        "print (f\"Average detailedDescription Length: {df.detailedDescription_tokenLength.mean()}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T20:46:44.670003Z",
          "iopub.execute_input": "2024-06-30T20:46:44.670842Z",
          "iopub.status.idle": "2024-06-30T20:46:48.621485Z",
          "shell.execute_reply.started": "2024-06-30T20:46:44.670811Z",
          "shell.execute_reply": "2024-06-30T20:46:48.620524Z"
        },
        "trusted": true,
        "id": "wY1rp8tcZEOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"briefTitle_maxtoken\"] = df.briefTitle.apply(lambda x: len(tokenizer.tokenize(x)))\n",
        "print (f\"Average briefTitle Maxium: {df.briefTitle_maxtoken.max()}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T20:46:51.320053Z",
          "iopub.execute_input": "2024-06-30T20:46:51.320456Z",
          "iopub.status.idle": "2024-06-30T20:46:51.386707Z",
          "shell.execute_reply.started": "2024-06-30T20:46:51.320424Z",
          "shell.execute_reply": "2024-06-30T20:46:51.385777Z"
        },
        "trusted": true,
        "id": "DGENXwNkZEOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"detailedDescription_MaxLength\"] = df.detailedDescription.apply(lambda x: len(tokenizer.tokenize(x)))\n",
        "\n",
        "print (f\" detailedDescription MAx Length: {df.detailedDescription_MaxLength.max()}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T20:46:53.019818Z",
          "iopub.execute_input": "2024-06-30T20:46:53.020538Z",
          "iopub.status.idle": "2024-06-30T20:46:54.141554Z",
          "shell.execute_reply.started": "2024-06-30T20:46:53.020505Z",
          "shell.execute_reply": "2024-06-30T20:46:54.140573Z"
        },
        "trusted": true,
        "id": "b4MKrXUxZEOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import json\n",
        "import os\n",
        "\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T20:47:20.429787Z",
          "iopub.execute_input": "2024-06-30T20:47:20.430464Z",
          "iopub.status.idle": "2024-06-30T20:47:20.438563Z",
          "shell.execute_reply.started": "2024-06-30T20:47:20.43043Z",
          "shell.execute_reply": "2024-06-30T20:47:20.437584Z"
        },
        "trusted": true,
        "id": "eEqNr36sZEOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "file = \"/kaggle/input/generate-titles-for-medical-journals/sample_titleGeneration_dataset.json\"\n",
        "with open(file) as input_file:\n",
        "    data = json.load(input_file)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T20:47:23.809761Z",
          "iopub.execute_input": "2024-06-30T20:47:23.81059Z",
          "iopub.status.idle": "2024-06-30T20:47:23.816436Z",
          "shell.execute_reply.started": "2024-06-30T20:47:23.810558Z",
          "shell.execute_reply": "2024-06-30T20:47:23.815532Z"
        },
        "trusted": true,
        "id": "pojM8-EAZEOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install evaluate rouge_score"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T17:05:38.583185Z",
          "iopub.execute_input": "2024-06-30T17:05:38.583955Z",
          "iopub.status.idle": "2024-06-30T17:05:51.232639Z",
          "shell.execute_reply.started": "2024-06-30T17:05:38.583916Z",
          "shell.execute_reply": "2024-06-30T17:05:51.231501Z"
        },
        "trusted": true,
        "id": "B9fzGKDaZEOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "rouge = evaluate.load('rouge')\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T17:06:15.548238Z",
          "iopub.execute_input": "2024-06-30T17:06:15.548711Z",
          "iopub.status.idle": "2024-06-30T17:06:16.006484Z",
          "shell.execute_reply.started": "2024-06-30T17:06:15.548677Z",
          "shell.execute_reply": "2024-06-30T17:06:16.005738Z"
        },
        "trusted": true,
        "id": "_ToR_BHvZEOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"The quick brown fox jumped over the lazy dog.\"\n",
        "text2 = \"The quick brown fox jumped over.\"\n",
        "text3 = \"Brown fox jumped.\"\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T17:06:32.977896Z",
          "iopub.execute_input": "2024-06-30T17:06:32.9786Z",
          "iopub.status.idle": "2024-06-30T17:06:32.983753Z",
          "shell.execute_reply.started": "2024-06-30T17:06:32.978566Z",
          "shell.execute_reply": "2024-06-30T17:06:32.982792Z"
        },
        "trusted": true,
        "id": "qfbn1BZEZEOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [text1]\n",
        "references = [text2]\n",
        "\n",
        "results = rouge.compute(predictions=predictions, references=references)\n",
        "print (results)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T17:06:35.578445Z",
          "iopub.execute_input": "2024-06-30T17:06:35.578936Z",
          "iopub.status.idle": "2024-06-30T17:06:35.811023Z",
          "shell.execute_reply.started": "2024-06-30T17:06:35.578907Z",
          "shell.execute_reply": "2024-06-30T17:06:35.810055Z"
        },
        "trusted": true,
        "id": "OxViQ_VTZEOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [text1]\n",
        "references = [text3]\n",
        "\n",
        "results = rouge.compute(predictions=predictions, references=references)\n",
        "print (results)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T17:06:39.823695Z",
          "iopub.execute_input": "2024-06-30T17:06:39.824595Z",
          "iopub.status.idle": "2024-06-30T17:06:40.034018Z",
          "shell.execute_reply.started": "2024-06-30T17:06:39.824559Z",
          "shell.execute_reply": "2024-06-30T17:06:40.032921Z"
        },
        "trusted": true,
        "id": "A19n9KkLZEOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import json\n",
        "import os\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T20:47:33.558269Z",
          "iopub.execute_input": "2024-06-30T20:47:33.558901Z",
          "iopub.status.idle": "2024-06-30T20:47:33.566647Z",
          "shell.execute_reply.started": "2024-06-30T20:47:33.558869Z",
          "shell.execute_reply": "2024-06-30T20:47:33.56581Z"
        },
        "trusted": true,
        "id": "6bE-pvICZEOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\tfile = \"/kaggle/input/generate-titles-for-medical-journals/sample_titleGeneration_dataset.json\"\n",
        "with open(file) as input_file:\n",
        "    data = json.load(input_file)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T20:47:36.259319Z",
          "iopub.execute_input": "2024-06-30T20:47:36.259931Z",
          "iopub.status.idle": "2024-06-30T20:47:36.2664Z",
          "shell.execute_reply.started": "2024-06-30T20:47:36.259899Z",
          "shell.execute_reply": "2024-06-30T20:47:36.265467Z"
        },
        "trusted": true,
        "id": "Sjb3ON-1ZEOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google-t5/t5-base\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"google-t5/t5-base\")\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T20:47:38.880006Z",
          "iopub.execute_input": "2024-06-30T20:47:38.880846Z",
          "iopub.status.idle": "2024-06-30T20:47:54.957509Z",
          "shell.execute_reply.started": "2024-06-30T20:47:38.880814Z",
          "shell.execute_reply": "2024-06-30T20:47:54.956599Z"
        },
        "trusted": true,
        "id": "Z6_fnGAoZEOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detailedDescription1 = data[0]['detailedDescription']\n",
        "briefTitle1 = data[0]['briefTitle']\n",
        "\n",
        "input_ids = tokenizer(f\"Brief: {detailedDescription1}\", return_tensors=\"pt\").input_ids\n",
        "outputs_ids = model.generate(input_ids, max_length=12)\n",
        "briefTitle1_gen = tokenizer.decode(outputs_ids[0], skip_special_tokens=True)\n",
        "\n",
        "print (f\"Actual: {briefTitle1}\")\n",
        "print (f\"Generated: {briefTitle1_gen}\")\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T20:49:21.609899Z",
          "iopub.execute_input": "2024-06-30T20:49:21.610753Z",
          "iopub.status.idle": "2024-06-30T20:49:22.32715Z",
          "shell.execute_reply.started": "2024-06-30T20:49:21.610719Z",
          "shell.execute_reply": "2024-06-30T20:49:22.326132Z"
        },
        "trusted": true,
        "id": "SJhasisMZEOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detailedDescription2 = data[1]['detailedDescription']\n",
        "briefTitle2 = data[1]['briefTitle']\n",
        "\n",
        "input_ids = tokenizer(f\"Brief: {detailedDescription2}\", return_tensors=\"pt\").input_ids\n",
        "outputs_ids = model.generate(input_ids, max_length=12)\n",
        "briefTitle2_gen = tokenizer.decode(outputs_ids[0], skip_special_tokens=True)\n",
        "\n",
        "print (f\"Actual: {briefTitle2}\")\n",
        "print (f\"Generated: {briefTitle2_gen}\")\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T20:49:28.019629Z",
          "iopub.execute_input": "2024-06-30T20:49:28.019994Z",
          "iopub.status.idle": "2024-06-30T20:49:28.653146Z",
          "shell.execute_reply.started": "2024-06-30T20:49:28.019951Z",
          "shell.execute_reply": "2024-06-30T20:49:28.652222Z"
        },
        "trusted": true,
        "id": "gNOdjLRtZEOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%pip install evaluate rouge_score\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T20:49:32.10978Z",
          "iopub.execute_input": "2024-06-30T20:49:32.11017Z",
          "iopub.status.idle": "2024-06-30T20:49:48.377341Z",
          "shell.execute_reply.started": "2024-06-30T20:49:32.110138Z",
          "shell.execute_reply": "2024-06-30T20:49:48.376209Z"
        },
        "trusted": true,
        "id": "9N7CLtXKZEOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "rouge = evaluate.load('rouge')\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T20:49:48.37956Z",
          "iopub.execute_input": "2024-06-30T20:49:48.379883Z",
          "iopub.status.idle": "2024-06-30T20:49:50.907076Z",
          "shell.execute_reply.started": "2024-06-30T20:49:48.379851Z",
          "shell.execute_reply": "2024-06-30T20:49:50.906086Z"
        },
        "trusted": true,
        "id": "74e4F7W4ZEOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [briefTitle1, briefTitle2]\n",
        "references = [briefTitle1_gen, briefTitle2_gen]\n",
        "\n",
        "results = rouge.compute(predictions=predictions, references=references)\n",
        "print (json.dumps(results, indent=4))\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T20:49:51.118588Z",
          "iopub.execute_input": "2024-06-30T20:49:51.118908Z",
          "iopub.status.idle": "2024-06-30T20:49:51.325212Z",
          "shell.execute_reply.started": "2024-06-30T20:49:51.118882Z",
          "shell.execute_reply": "2024-06-30T20:49:51.323868Z"
        },
        "trusted": true,
        "id": "Q_vqulkrZEOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detailedDescription1 = data[0]['detailedDescription']\n",
        "briefTitle1 = data[0]['briefTitle']\n",
        "\n",
        "input_ids = tokenizer(f\"Brief: {detailedDescription1}\", return_tensors=\"pt\").input_ids\n",
        "outputs_ids = model.generate(input_ids, max_length=12, min_length=5, temperature=0.4, top_k=100)\n",
        "briefTitle1_gen = tokenizer.decode(outputs_ids[0], skip_special_tokens=True)\n",
        "\n",
        "print (f\"Actual: {briefTitle1}\")\n",
        "print (f\"Generated: {briefTitle1_gen}\")\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T20:49:58.661041Z",
          "iopub.execute_input": "2024-06-30T20:49:58.661404Z",
          "iopub.status.idle": "2024-06-30T20:49:59.301275Z",
          "shell.execute_reply.started": "2024-06-30T20:49:58.661378Z",
          "shell.execute_reply": "2024-06-30T20:49:59.300332Z"
        },
        "trusted": true,
        "id": "ru0PlLIOZEOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset\n",
        "\n",
        "np.random.seed(100)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T20:50:08.35005Z",
          "iopub.execute_input": "2024-06-30T20:50:08.350955Z",
          "iopub.status.idle": "2024-06-30T20:50:08.355525Z",
          "shell.execute_reply.started": "2024-06-30T20:50:08.350919Z",
          "shell.execute_reply": "2024-06-30T20:50:08.354449Z"
        },
        "trusted": true,
        "id": "yvnzFVcFZEOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/kaggle/input/generate-titles-for-medical-journals/titleGeneration_dataset.json\", \"r\") as f:\n",
        "    data =json.load(f)\n",
        "\n",
        "df = pd.DataFrame(data)[0:5000]\n",
        "df_train, df_test = train_test_split(df, test_size=0.10)\n",
        "\n",
        "dataset_train = Dataset.from_pandas(df_train, split=\"train\")\n",
        "dataset_test = Dataset.from_pandas(df_test, split=\"test\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T20:50:16.309867Z",
          "iopub.execute_input": "2024-06-30T20:50:16.310735Z",
          "iopub.status.idle": "2024-06-30T20:50:18.263013Z",
          "shell.execute_reply.started": "2024-06-30T20:50:16.310701Z",
          "shell.execute_reply": "2024-06-30T20:50:18.262252Z"
        },
        "trusted": true,
        "id": "ZLVBYl0kZEOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import AutoTokenizer, DataCollatorForSeq2Seq\n",
        "\n",
        "model_name = \"google-t5/t5-small\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def preprocess_data(rows):\n",
        "    inputs = tokenizer(rows[\"detailedDescription\"], max_length=2048, truncation=True, padding=True)\n",
        "    labels = tokenizer(rows[\"briefTitle\"], max_length=12, truncation=True, padding=True)\n",
        "\n",
        "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "\n",
        "    return inputs\n",
        "\n",
        "tok_dataset_train = dataset_train.map(preprocess_data, batched=True)\n",
        "tok_dataset_test = dataset_test.map(preprocess_data, batched=True)\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer=tokenizer, model=model_name, padding=True\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T20:50:20.976406Z",
          "iopub.execute_input": "2024-06-30T20:50:20.977377Z",
          "iopub.status.idle": "2024-06-30T20:50:30.441294Z",
          "shell.execute_reply.started": "2024-06-30T20:50:20.977333Z",
          "shell.execute_reply": "2024-06-30T20:50:30.440163Z"
        },
        "trusted": true,
        "id": "VlDxR8thZEOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install evaluate rouge_score\n",
        "\n",
        "import evaluate\n",
        "\n",
        "rouge = evaluate.load('rouge')\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    pred_ids = eval_pred.predictions[0]\n",
        "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "\n",
        "    labels_ids = eval_pred.label_ids\n",
        "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T20:51:27.66972Z",
          "iopub.execute_input": "2024-06-30T20:51:27.670116Z",
          "iopub.status.idle": "2024-06-30T20:51:41.143006Z",
          "shell.execute_reply.started": "2024-06-30T20:51:27.670084Z",
          "shell.execute_reply": "2024-06-30T20:51:41.142172Z"
        },
        "trusted": true,
        "id": "EBsqf-9FZEOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
        "\n",
        "rouge_output = rouge.compute(\n",
        "        predictions=pred_str,\n",
        "        references=label_str,\n",
        "        rouge_types=[\"rouge1\", \"rouge2\", \"rouge3\", \"rougeL\", \"rougeLsum\"],\n",
        "    )\n",
        "\n",
        "return {\n",
        "        \"R1\": round(rouge_output[\"rouge1\"], 4),\n",
        "        \"R2\": round(rouge_output[\"rouge2\"], 4),\n",
        "        \"R3\": round(rouge_output[\"rouge3\"], 4),\n",
        "        \"RL\": round(rouge_output[\"rougeL\"], 4),\n",
        "        \"RLsum\": round(rouge_output[\"rougeLsum\"], 4),\n",
        "    }\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T20:51:45.186114Z",
          "iopub.execute_input": "2024-06-30T20:51:45.186765Z",
          "iopub.status.idle": "2024-06-30T20:51:45.234077Z",
          "shell.execute_reply.started": "2024-06-30T20:51:45.18673Z",
          "shell.execute_reply": "2024-06-30T20:51:45.23267Z"
        },
        "trusted": true,
        "id": "XbGsIwCIZEOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install evaluate rouge_score"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T17:10:14.718259Z",
          "iopub.execute_input": "2024-06-30T17:10:14.718646Z",
          "iopub.status.idle": "2024-06-30T17:10:27.16707Z",
          "shell.execute_reply.started": "2024-06-30T17:10:14.718615Z",
          "shell.execute_reply": "2024-06-30T17:10:27.165894Z"
        },
        "trusted": true,
        "id": "hMPypoZtZEOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T17:10:30.033442Z",
          "iopub.execute_input": "2024-06-30T17:10:30.034401Z",
          "iopub.status.idle": "2024-06-30T17:10:30.038888Z",
          "shell.execute_reply.started": "2024-06-30T17:10:30.034366Z",
          "shell.execute_reply": "2024-06-30T17:10:30.03792Z"
        },
        "trusted": true,
        "id": "DceRFdRtZEOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rouge = evaluate.load('rouge')\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    pred_ids = eval_pred.predictions[0]\n",
        "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "\n",
        "    labels_ids = eval_pred.label_ids\n",
        "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
        "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
        "\n",
        "    rouge_output = rouge.compute(\n",
        "        predictions=pred_str,\n",
        "        references=label_str,\n",
        "        rouge_types=[\"rouge1\", \"rouge2\", \"rouge3\", \"rougeL\", \"rougeLsum\"],\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"R1\": round(rouge_output[\"rouge1\"], 4),\n",
        "        \"R2\": round(rouge_output[\"rouge2\"], 4),\n",
        "        \"R3\": round(rouge_output[\"rouge3\"], 4),\n",
        "        \"RL\": round(rouge_output[\"rougeL\"], 4),\n",
        "        \"RLsum\": round(rouge_output[\"rougeLsum\"], 4),\n",
        "    }\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T20:51:56.800441Z",
          "iopub.execute_input": "2024-06-30T20:51:56.800805Z",
          "iopub.status.idle": "2024-06-30T20:51:57.855297Z",
          "shell.execute_reply.started": "2024-06-30T20:51:56.800774Z",
          "shell.execute_reply": "2024-06-30T20:51:57.854492Z"
        },
        "trusted": true,
        "id": "fsK9O__BZEOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoConfig\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T20:52:06.7699Z",
          "iopub.execute_input": "2024-06-30T20:52:06.770775Z",
          "iopub.status.idle": "2024-06-30T20:52:06.775331Z",
          "shell.execute_reply.started": "2024-06-30T20:52:06.770741Z",
          "shell.execute_reply": "2024-06-30T20:52:06.774239Z"
        },
        "trusted": true,
        "id": "gCEIaWshZEOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_logits_for_metrics(logits, labels):\n",
        "    pred_ids = torch.argmax(logits[0], dim=-1)\n",
        "    return pred_ids, labels\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer=tokenizer, model=model_name, padding=True\n",
        ")\n",
        "\n",
        "config = AutoConfig.from_pretrained(\n",
        "    model_name\n",
        ")\n",
        "config.use_cache = False\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "    model_name,\n",
        "    config=config,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "\n",
        "# Training Arguments\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    # Training Hypermparameters\n",
        "    num_train_epochs=1,\n",
        "    # Optimizer Hyperparameters\n",
        "learning_rate=1e-4,\n",
        "    warmup_steps=100,\n",
        "    # Logging Hyperparameters\n",
        "    run_name=\"title_generator\",\n",
        "    output_dir=\"title_generator\",\n",
        "    overwrite_output_dir=False,\n",
        "    logging_steps=20,\n",
        "    eval_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=20,\n",
        "    # Quantization to save memory (lower precision)\n",
        "    fp16=False,\n",
        "    # External Reporting\n",
        "    report_to=\"none\",\n",
        "    # General Hyperparameters\n",
        "    auto_find_batch_size=True,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=16,\n",
        "    predict_with_generate=False,\n",
        "    push_to_hub=False,\n",
        "    save_total_limit=2,\n",
        "    gradient_checkpointing=True,\n",
        "    gradient_checkpointing_kwargs={'use_reentrant':False},\n",
        "    do_train=True\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tok_dataset_train,\n",
        "    eval_dataset=tok_dataset_test,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    preprocess_logits_for_metrics=preprocess_logits_for_metrics\n",
        ")\n",
        "\n",
        "# Train\n",
        "trainer.train(resume_from_checkpoint=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T20:53:06.280581Z",
          "iopub.execute_input": "2024-06-30T20:53:06.280978Z",
          "iopub.status.idle": "2024-06-30T21:13:08.394476Z",
          "shell.execute_reply.started": "2024-06-30T20:53:06.280926Z",
          "shell.execute_reply": "2024-06-30T21:13:08.393387Z"
        },
        "trusted": true,
        "id": "XSmU60HZZEOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "description = \"This is a prospective, non-randomized, open-label, single-center, \\\n",
        "pilot study in subjects with normal pressure hydrocephalus for whom a traditional \\\n",
        "CSF shunt implant is indicated.\\n\\nUp to 30 subjects will receive the eShunt Implant \\\n",
        "at one investigational site. Subjects will return for five follow-up visits in the first \\\n",
        "year and then continue to attend visits every six months for five years post-implantation. \\\n",
        "\\n\\nThe study objectives are to demonstrate safety of the eShunt Procedure, as well as \\\n",
        "demonstrate safety and efficacy of the eShunt Implant in a small sample of patients. \\\n",
        "\\n\\nSubjects will be followed long-term; primary analysis results will be used to support \\\n",
        "additional studies.\"\n",
        "\n",
        "input_ids = tokenizer(description, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
        "outputs = model.generate(input_ids, max_length=12)\n",
        "title = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "\n",
        "print (f\"Generated: {title}\")\n",
        "print (\"Actual: Pilot Study of the CereVasc(r) eShunt(r) System in Normal Pressure Hydrocephalus\")\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T21:18:34.428914Z",
          "iopub.execute_input": "2024-06-30T21:18:34.429305Z",
          "iopub.status.idle": "2024-06-30T21:18:34.561365Z",
          "shell.execute_reply.started": "2024-06-30T21:18:34.429273Z",
          "shell.execute_reply": "2024-06-30T21:18:34.560455Z"
        },
        "trusted": true,
        "id": "WjDV9HFNZEOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "description = \"Twelve RYGB candidates who were successfully treated with an SRI for primary mood or anxiety disorders were studied prospectively. Blood samples for SRI plasma levels were drawn immediately after dose for pharmacokinetic studies (PK) preoperatively. Maximum concentration (CMAX), time to CMAX (TMAX), and Area Under Concentration/Time curve (AUC) were determined. PK studies were repeated at one, six, and twelve months post-operatively. PK data were corrected for dose at each study time point. The Structured Interview Guide for the Hamilton Depression Rating Scale- Atypical Depression Symptom Version was used to quantify depressive symptoms.\"\n",
        "\n",
        "input_ids = tokenizer(description, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
        "outputs = peft_model.generate(input_ids=input_ids, max_length=12)\n",
        "title = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "\n",
        "print (f\"Generated: {title}\")\n",
        "print (\"Actual: The Effect of Gastric Bypass on the Pharmacokinetics of Serotonin Reuptake Inhibitors\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-30T21:18:38.945746Z",
          "iopub.execute_input": "2024-06-30T21:18:38.946226Z",
          "iopub.status.idle": "2024-06-30T21:18:38.99032Z",
          "shell.execute_reply.started": "2024-06-30T21:18:38.946192Z",
          "shell.execute_reply": "2024-06-30T21:18:38.989047Z"
        },
        "trusted": true,
        "id": "oVbdOK0dZEOo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}